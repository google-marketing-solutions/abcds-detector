{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbQ34wkyzuMv"
      },
      "source": [
        "```\n",
        "Copyright 2024 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV5fR3sotHXp"
      },
      "source": [
        "# ABCDs Detector\n",
        "\n",
        "The ABCDs Detector solution offers a streamlined solution for understanding how video ads align with key metrics within the [YouTube ABCD Framework](https://www.thinkwithgoogle.com/intl/en-emea/future-of-marketing/creativity/youtube-video-ad-best-practices/). Powered by Google AI, the tool leverages a data-driven analysis to automate the ABCD assessment, providing an objective and comprehensive report of adherence across a collection of defined features. By combining **Video** And **LLM** Google AI models, ABCDs Detector automates the evaluation process and delivers comprehensive reports on how well your ads align with the ABCD framework. This empowers you to optimize your YouTube ad campaigns for maximum impact."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDLbAgObvWGv"
      },
      "source": [
        "## Video Intelligence API (Video)\n",
        "\n",
        "Google AI extracts features and identifies key moments within your video ads. See [Google Video Intelligence API](https://cloud.google.com/video-intelligence?hl=en) documentation.\n",
        "\n",
        "### Features Used\n",
        "  - Label annotations\n",
        "  - Face annotations\n",
        "  - Text annotations\n",
        "  - Object annotations\n",
        "  - People annotations\n",
        "  - Speech annotations\n",
        "  - Shot annotations\n",
        "  - Logo annotations\n",
        "\n",
        "### Cost\n",
        "Prices are per minute. Partial minutes are rounded up to the next full minute. Volume is per month. For more details please check the official [documentation](https://cloud.google.com/video-intelligence/pricing).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCRbyHkLt4Di"
      },
      "source": [
        "## Gemini Pro (LLM)\n",
        "\n",
        "LLMs are used to assess features against YouTube's ABCD framework rubrics. This enables the detector to \"ask questions\" and determine if the ad adheres to each rubric.  See [Vertex AI](https://cloud.google.com/vertex-ai) documentation.\n",
        "\n",
        "### Prompts\n",
        "\n",
        "ABCDs Detector will perform 2 verifications, first with annotations and then with LLMs. Since the LLM approach is prone to hallucinations, False Positives or False Negatives will be expected. The solution will still require human QA if 100% accuracy is required for the evaluation.\n",
        "\n",
        "ABCDs Detector MVP supports a single video evaluation for the following features/rubrics:\n",
        "  - Quick Pacing\n",
        "  - Quick Pacing (First 5 seconds)\n",
        "  - Dynamic Start\n",
        "  - Supers\n",
        "  - Supers with Audio\n",
        "  - Brand Visuals\n",
        "  - Brand Visuals (First 5 seconds)\n",
        "  - Brand Mention (Speech)\n",
        "  - Brand Mention (Speech) (First 5 seconds)\n",
        "  - Product Visuals\n",
        "  - Product Visuals (First 5 seconds)\n",
        "  - Product Mention (Text)\n",
        "  - Product Mention (Text) (First 5 seconds)\n",
        "  - Product Mention (Speech)\n",
        "  - Product Mention (Speech) (First 5 seconds)\n",
        "  - Visible Face (First 5 seconds)\n",
        "  - Visible Face (Close Up)\n",
        "  - Presence of People\n",
        "  - Presence of People (First 5 seconds)\n",
        "  - Overall Pacing\n",
        "  - Audio Speech Early\n",
        "  - Call To Action (Text)\n",
        "  - Call To Action (Speech)\n",
        "\n",
        "### Cost\n",
        "With the Multimodal models in Vertex AI, you can input either text or media (images, video). Text input is charged by every 1,000 characters of input (prompt) and every 1,000 characters of output (response). Characters are counted by UTF-8 code points and white space is excluded from the count. Prediction requests that lead to filtered responses are charged for the input only. At the end of each billing cycle, fractions of one cent ($0.01) are rounded to one cent. Media input is charged per image or per second (video). For more details please check the official documentation: https://cloud.google.com/vertex-ai/generative-ai/pricing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7rvNc74z-b5"
      },
      "source": [
        "# Requirements\n",
        "Please esure you have access to all of the following before starting:\n",
        "* [Google Cloud Project](https://cloud.google.com) with enabled APIs:\n",
        "    * [Video Intelligence API](https://console.cloud.google.com/marketplace/product/google/videointelligence.googleapis.com)\n",
        "    * [Vertex AI API](https://console.cloud.google.com/marketplace/product/google/aiplatform.googleapis.com)\n",
        "    * [Knowledge Graph API](https://console.cloud.google.com/marketplace/product/google/kgsearch.googleapis.com)\n",
        "    * [Cloud Storage API](https://console.cloud.google.com/marketplace/product/google/storage.googleapis.com)\n",
        "* [API Key](https://cloud.google.com/docs/authentication/api-keys) provisioned.\n",
        "* [Project Billing](https://cloud.google.google.com/billing/) enabled.\n",
        "* Python libraries:\n",
        "    * `google-cloud-videointelligence`\n",
        "    * `google-cloud-aiplatform`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHqQskKjxtEk"
      },
      "source": [
        "# Instructions\n",
        "Please follow the steps below before executing the ABCDs Detector solution. Every **[VARIABLE]** is a parameter you can configure in the **Define ABCDs Detector Parameters** section.\n",
        "\n",
        "1. Store your videos on [Google Cloud Storage](https://console.cloud.google.com/storage/browser).\n",
        "   * **[BUCKET_NAME]** - the place where this tool will store annotation data under **ABCD** folder. Clear this to redo annotations.\n",
        "   * **[VIDEO_URIS]** - a list of video URIs that will be processed, can be any path but should match brand information.\n",
        "      * If the URI is a file if will be evaluated as is.\n",
        "      * If the URI is a folder path that ends with **/**, then it will be expanded, all the files in that path will be evaluated.\n",
        "\n",
        "1. Make sure the requirements are met:\n",
        "   * Enable APIs:\n",
        "      * [Video Intelligence API](https://console.cloud.google.com/marketplace/product/google/videointelligence.googleapis.com)\n",
        "      * [Vertex AI API](https://console.cloud.google.com/marketplace/product/google/aiplatform.googleapis.com)\n",
        "      * [Knowledge Graph API](https://console.cloud.google.com/marketplace/product/google/kgsearch.googleapis.com)\n",
        "      * [Cloud Storage API](https://console.cloud.google.com/marketplace/product/google/storage.googleapis.com)\n",
        "   * Provision [An API Key](https://cloud.google.com/docs/authentication/api-keys):\n",
        "      1. Visit [Credentials Page](https://cloud.console.google.com/apis/credentials).\n",
        "      1. Create a **New API Key** and copy it into **[KNOWLEDGE_GRAPH_API_KEY]** below.\n",
        "      1. We recommend editing and restricting the key to the above APIs.\n",
        "\n",
        "1. Define all the parameters.\n",
        "   * Required:\n",
        "      * Google Cloud Project Details\n",
        "      * Brand And Product Details\n",
        "   * Optional\n",
        "      * Solution Setup\n",
        "      * ABCD Framework Details\n",
        "      * LLM Configuration\n",
        "\n",
        "1. Run all of the steps in sequence.\n",
        "   * Some steps do not produce output, they only define functions.\n",
        "   * If a step asks you to **Restart Runtime**, do so.\n",
        "   * If a step displays an error, stop and debug it. Debug the following:\n",
        "      * APIs are enabled.\n",
        "      * Storage bucket is correctly configured.\n",
        "      * The video is the correct size.\n",
        "      * API Key has correct restrictions.\n",
        "      * Previous code sections completed.\n",
        "      * Select _Runtime > Reset Session and Run All_ as a last resort.\n",
        "   * The **Run ABCDs Detector** step produces the video analysis.\n",
        "\n",
        "1. For questions, please reach out to: abcds-detector@google.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-VVH3V36y8y"
      },
      "source": [
        "# Install ABCD Detector Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KlVPryttrZr"
      },
      "outputs": [],
      "source": [
        "!git clone -b main https://github.com/google-marketing-solutions/abcds-detector\n",
        "!python3 -m pip install -r \"abcds-detector/requirements.txt\"\n",
        "%cd /content/abcds-detector\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-VVH3V36y8w"
      },
      "source": [
        "# Define ABCDs Detector Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myojeXOC0UYJ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "###########################################################################\n",
        "#\n",
        "#  Copyright 2024 Google LLC\n",
        "#\n",
        "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "#  you may not use this file except in compliance with the License.\n",
        "#  You may obtain a copy of the License at\n",
        "#\n",
        "#      https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "#  Unless required by applicable law or agreed to in writing, software\n",
        "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "#  See the License for the specific language governing permissions and\n",
        "#  limitations under the License.\n",
        "#\n",
        "###########################################################################\n",
        "\n",
        "from configuration import Configuration\n",
        "config = Configuration()\n",
        "\n",
        "# @markdown ### Google Cloud Project Details\n",
        "\n",
        "PROJECT_ID = \"\"  # @param {type:\"string\", placeholder:\"Google Cloud Project ID\"}\n",
        "PROJECT_ZONE = \"us-central1\"# @param {type:\"string\", placeholder:\"Google Cloud Project Zone\"}\n",
        "BUCKET_NAME = \"\"  # @param {type:\"string\", placeholder:\"Google Cloud Sotrage Bucket for annotations\"}\n",
        "KNOWLEDGE_GRAPH_API_KEY = \"\"  # @param {type:\"string\", placeholder:\"Google Cloud Project API Key\"}\n",
        "BQ_DATASET_NAME = \"abcd_detector_ds\" # @param {type:\"string\"}\n",
        "BQ_TABLE_NAME = \"abcd_assessments\" # @param {type:\"string\"}\n",
        "ASSESSMENT_FILE = \"\"  # @param {type:\"string\", placeholder:\"optional local file to write assesments to\"}\n",
        "USE_ANNOTATIONS = True  # @param {type:\"boolean\"}\n",
        "USE_LLMS = True  # @param {type:\"boolean\"}\n",
        "VERBOSE = True  # @param {type:\"boolean\"}\n",
        "\n",
        "config.set_parameters(\n",
        "    project_id = PROJECT_ID,\n",
        "    project_zone = PROJECT_ZONE,\n",
        "    bucket_name = BUCKET_NAME,\n",
        "    knowledge_graph_api_key = KNOWLEDGE_GRAPH_API_KEY,\n",
        "    bigquery_dataset = BQ_DATASET_NAME,\n",
        "    bigquery_table = BQ_TABLE_NAME,\n",
        "    assessment_file = ASSESSMENT_FILE,\n",
        "    use_annotations = USE_ANNOTATIONS,\n",
        "    use_llms = USE_LLMS,\n",
        "    verbose = VERBOSE\n",
        ")\n",
        "\n",
        "\n",
        "# @markdown ### Brand and Product Details\n",
        "\n",
        "BRAND_NAME = \"Google\"  # @param {type:\"string\"}\n",
        "BRAND_VARIATIONS = \"google\"  # @param {type:\"string\"}\n",
        "BRANDED_PRODUCTS = \"Google pixel, Google pixel buds, Google pixel watch\"  # @param {type:\"string\"}\n",
        "BRANDED_PRODUCT_CATEGORIES = \"phone, watch, buds\"  # @param {type:\"string\"}\n",
        "BRANDED_CALL_TO_ACTIONS = \"buy it!\"  # @param {type:\"string\"}\n",
        "\n",
        "config.set_brand_details(\n",
        "    brand_name = BRAND_NAME,\n",
        "    brand_variations = BRAND_VARIATIONS,\n",
        "    products = BRANDED_PRODUCTS,\n",
        "    products_categories = BRANDED_PRODUCT_CATEGORIES,\n",
        "    call_to_actions = BRANDED_CALL_TO_ACTIONS\n",
        ")\n",
        "\n",
        "# @markdown ### ABCD Framework Details\n",
        "\n",
        "EARLY_TIME_SECONDS = 5\n",
        "CONFIDENCE_THRESHOLD = 0.5  # @param {type:\"number\"}\n",
        "FACE_SURFACE_THRESHOLD = 0.15  # @param {type:\"number\"}\n",
        "LOGO_SIZE_THRESHOLD = 3.5  # @param {type:\"number\"}\n",
        "AVG_SHOT_DURATION_SECONDS = 2  # @param {type:\"number\"}\n",
        "DYNAMIC_CUTOFF_MS = 3000  # @param {type:\"number\"}\n",
        "\n",
        "config.set_annotation(\n",
        "    early_time_seconds = EARLY_TIME_SECONDS,\n",
        "    confidence_threshold = CONFIDENCE_THRESHOLD,\n",
        "    face_surface_threshold =  FACE_SURFACE_THRESHOLD,\n",
        "    logo_size_threshold = LOGO_SIZE_THRESHOLD,\n",
        "    avg_shot_duration_seconds = AVG_SHOT_DURATION_SECONDS,\n",
        "    dynamic_cutoff_ms = DYNAMIC_CUTOFF_MS\n",
        ")\n",
        "\n",
        "# @markdown ### LLM Configuration\n",
        "\n",
        "LLM_NAME = \"gemini-2.0-flash-001\"  # @param {type:\"string\"}\n",
        "VIDEO_SIZE_LIMIT_MB = 50  # @param {type:\"number\"}\n",
        "MAX_OUTPUT_TOKENS = 8192  # @param {type:\"number\"}\n",
        "TEMPERATURE = 1  # @param {type:\"number\"}\n",
        "TOP_P = 0.95  # @param {type:\"number\"}\n",
        "TOP_K = 32  # @param {type:\"number\"}\n",
        "\n",
        "config.set_model(\n",
        "    llm_name = LLM_NAME,\n",
        "    video_size_limit_mb = VIDEO_SIZE_LIMIT_MB,\n",
        "    max_output_tokens = MAX_OUTPUT_TOKENS,\n",
        "    temperature = TEMPERATURE,\n",
        "    top_p = TOP_P,\n",
        "    top_k = TOP_K\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-MyTk6LvvM9"
      },
      "source": [
        "# Get Video URIs\n",
        "You can analyze any video in any project you have access to. The following list takes two possible inputs:\n",
        "\n",
        "   1. A Google [Cloud Storage URI](https://console.cloud.google.com/storage/) by clicking the **:** icon on the right of a video and selecting **Copy gsutil URI**. The path must be a video file.\n",
        "   2. A folder path to load all videos in a folder, just remove the video part so the path ends in a forward slash like **gs://????/**.\n",
        "\n",
        "### Example Code\n",
        "\n",
        "```\n",
        "config.set_videos([\n",
        "  \"gs://cloud-samples-data/generative-ai/video/pixel8.mp4\",\n",
        "  \"gs://cloud-samples-data/generative-ai/video/\"  \n",
        "])\n",
        "```\n",
        "\n",
        "Please fill the videos in the next section..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config.set_videos([\n",
        "  \"gs://abcd-detector-input/Google/videos/\",\n",
        "])"
      ],
      "metadata": {
        "id": "g7ehWDRtQxjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz86-SgmRBc7"
      },
      "source": [
        "# Authenticate ABCDs Detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ovcu5_OXGHy_"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user(project_id=config.project_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pg9ZT-CERKzg"
      },
      "source": [
        "# Run ABCDs Detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-92Uo3Ova_g"
      },
      "outputs": [],
      "source": [
        "from main import execute_abcd_assessment_for_videos\n",
        "execute_abcd_assessment_for_videos(config)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}